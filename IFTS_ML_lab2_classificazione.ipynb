{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IFTS** TECNICO DEL DISEGNO E PROGETTAZIONE INDUSTRIALE SPECIALIZZATO IN SMART MANUFACTURING (2019)  \n",
    "**INDUSTRIA 4.0 - Tecnologie Informatiche di Riferimento**\n",
    "\n",
    "# Machine Learning\n",
    "\n",
    "## Esercitazione 2: Classificazione\n",
    "\n",
    "Gianluca Moro, **Roberto Pasolini**  \n",
    "DISI - Dipartimento di Informatica - Scienza e Ingegneria  \n",
    "Università di Bologna  \n",
    "nome.cognome@unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esempio 3: valutazione del rischio di credito\n",
    "\n",
    "Una banca vuole ottenere un modello per la valutazione del rischio nella concessione di prestiti. Per questo ha a disposizione un insieme di casi già etichettati come \"sicuri\" o \"a rischio\".\n",
    "\n",
    "Si tratta di un problema di classificazione: per ogni nuovo caso, il modello deve indicare una di queste due etichette.\n",
    "\n",
    "Iniziamo caricando i dati, che si trovano nel file CSV `bank.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"bank.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo il numero di righe e di colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo alcuni esempi di dati dalle prime righe (`head`) e dalle ultime (`tail`); nella visualizzazione alcune colonne sono omesse per brevità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colonna \"Risk\" sulla destra è ciò che vogliamo predire: è \"Good\" per i clienti considerati sicuri e \"Bad\" per quelli considerati a rischio. Possiamo usare la funzione `value_counts` per vedere quanti esempi sono presenti di un tipo e dell'altro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Risk\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per iniziare, come abbiamo fatto negli esempi con la regressione, dividiamo i dati in un training set per addestrare i modelli e in un validation set per valutarne l'accuratezza, distinguendo la variabile che vogliamo predire (\"Risk\") da quelle su cui vogliamo basare la predizione (tutte le altre)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(data.drop(columns=[\"Risk\"]), data[\"Risk\"], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversione variabili categoriche\n",
    "\n",
    "Nella tabella sono presenti due tipi di variabili: quelle _numeriche_ in cui ciascun valore è un numero (es. \"Amount\", \"InstallmentRate\", ecc.) e quelle _categoriche_ i cui valori possibili sono ristretti ad un insieme specifico (es. \"Sex\" può essere \"Male\" o \"Female\").\n",
    "\n",
    "Diversi algoritmi di ML possono gestire solamente variabili di tipo numerico. Tuttavia ogni variabile di tipo categorico con N valori possibili può essere facilmente convertita in N variabili numeriche: ciascuna variabile avrà valore 1 nei casi in cui la variabile categorica ha il valore che rappresenta e 0 negli altri casi. Tale codifica delle variabili categoriche è detta _one-hot encoding_.\n",
    "\n",
    "Definiamo una funzione che sostituisca le variabili categoriche con tale codifica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(df):\n",
    "    return pd.concat(\n",
    "        [pd.get_dummies(df[col], col) if df[col].dtype == object else df[[col]]\n",
    "         for col in df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applichiamola quindi alle tabelle `X_train` e `X_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = encode_categorical(X_train)\n",
    "X_val = encode_categorical(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutte le variabili predittive (X) sono ora numeriche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alberi decisionali\n",
    "\n",
    "Gli _alberi decisionali_ sono una classe di modelli di classificazione molto usati nella pratica. Dai dati di addestramento viene costruito un diagramma ad albero, per classificare un elemento si segue un percorso dalla radice dell'albero ad una \"foglia\" con la classe predetta in base ai valori delle variabili. Tale modello ha il vantaggio di essere semplice da interpretare: osservando l'albero generato è immediato capire quali siano le variabili più importanti ai fini della predizione.\n",
    "\n",
    "L'uso di modelli di classificazione in scikit-learn è simile a quello dei modelli di regressione: iniziamo caricando la classe dei modelli che vogliamo usare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inizializziamo quindi un modello definendone i parametri: in questo caso usiamo `max_depth` che limita la profondità dell'albero e `random_state` che fissa le scelte casuali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=10, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per addestrare il modello usiamo la funzione `fit` passando le variabili predittive (X) e i valori da prevedere (y) come nella regressione, con la differenza che quì i valori y sono le etichette \"Good\" e \"Bad\" invece di numeri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello che si ottiene è simile a questo:\n",
    "\n",
    "![albero decisionale](tree.svg)\n",
    "\n",
    "Per classificare un esempio si parte dal nodo radice in alto, quindi in ogni nodo si verifica il valore della variabile indicata (ad es. `AccountStatus_NoAccount` nella radice) e si segue il ramo sinistro o destro a seconda che sia sotto o sopra la soglia indicata. Si prosegue fino a raggiungere un nodo foglia (quelli in basso), che indica la classe predetta. Le variabili che compaiono ai livelli superiori sono in genere quelle più d'aiuto nel distinguere gli esempi delle diverse classi.\n",
    "\n",
    "Per ottenere predizioni dal modello possiamo usare `predict` come per i modelli di regressione. Otteniamo ad esempio le predizioni relative ai primi 5 esempi del validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_val.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I modelli di classificazione forniscono anche la funzione `predict_proba`, che indica le probabilità stimate dal modello per ciascuna classe, in caso sia necessario distinguere le predizioni più sicure da quelle più incerte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.predict_proba(X_val.head(5)), columns=model.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ad es. la predizione \"Bad\" sul primo esempio è data certa (100%), mentre sul terzo c'è una minima incertezza (98%).\n",
    "\n",
    "Per valutare l'accuratezza del modello anche in questo caso possiamo usare la funzione `score` passando i dati del validation set. Nel caso della classificazione, la metrica di accuratezza è la percentuale di casi del validation set che vengono classificati correttamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significa che circa il 60% degli esempi è classificato correttamente.\n",
    "\n",
    "Un'indicazione più specifica sull'efficacia del modello può essere data dalla _matrice di confusione_, che indica il numero di esempi per ogni combinazione possibile di classe reale e classe predetta. Per estrarre tale matrice usiamo la funzione `confusion_matrix` passando la serie delle classi reali del validation `y_val` e quelle predette dal modello, ottenute tramite `predict`. L'ultima riga del codice sotto serve a visualizzare la matrice in modo comprensibile con righe e colonne etichettate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_val, model.predict(X_val), labels=model.classes_)\n",
    "pd.DataFrame(cm, index=model.classes_, columns=model.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa matrice indica ad esempio che, delle 80 istanze \"Bad\" del validation set, 47 sono state effettivamente etichettate come \"Bad\" mentre 33 sono state erroneamente etichettate \"Good\". In pratica il modello ha erroneamente previsto come \"sicuri\" 33 clienti a rischio.\n",
    "\n",
    "Considerare la matrice di confusione invece della sola accuratezza è molto importante nel caso in cui gli errori abbiano costi differenti. Ad esempio una banca potrebbe perdere molti più soldi concedendo un prestito che non viene restituito piuttosto che non concedendone uno che verrebbe restituito, per cui può cercare di ottenere un modello che minimizzi gli errori del primo tipo considerando meno gravi gli altri.\n",
    "\n",
    "Addestriamo un altro modello diminuendo il parametro `max_depth`, quindi limitando ancora di più la profondità dell'albero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5, random_state=123)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_val, model.predict(X_val), labels=model.classes_)\n",
    "pd.DataFrame(cm, index=model.classes_, columns=model.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo secondo albero decisionale compie meno errori del primo nonostante sia più semplice: può essere segno di _overfitting_ nel primo albero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "Un altro esempio di modello di classificazione sono le _Support Vector Machine_ (SVM); tali modelli astraggono i dati come punti in uno spazio multidimensionale e cercano il piano che divide in modo più netto possibile i punti di una classe da quelli dell'altra. Come la regressione kernel ridge, SVM si basa su funzioni kernel per riuscire a separare classi anche in modo non lineare.\n",
    "\n",
    "La classe `SVC` implementa i modelli di classificazione tramite SVM (esistono anche modelli SVM per la regressione). Il funzionamento è simile agli altri..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(gamma=\"auto\")\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo modello è meno accurato del precedente basato su albero decisionale, ma SVM è generalmente più efficace nella classificazione di testi, come vediamo di seguito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esempio 4: classificazione di commenti positivi e negativi\n",
    "\n",
    "Vediamo ora come creare un modello che riconosca commenti positivi o negativi addestrandolo su recensioni già etichettate.\n",
    "\n",
    "Il file all'URL `https://git.io/vpaDt` contiene 10.000 recensioni di film estratte da Amazon, etichettate col numero di stelle dato dall'utente da 1 a 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"https://git.io/vpaDt\", sep=\"\\t\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo alcune di queste recensioni. La prima riga serve ad aumentare il numero massimo di caratteri mostrato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100\n",
    "reviews.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per dividere le recensioni in due classi, etichettiamo come \"positive\" quelle con 4 o 5 stelle e come \"negative\" le altre con 3 stelle o meno. Aggiungiamo alla tabella una colonna \"etichetta\" che valga \"pos\" o \"neg\" a seconda di questa condizione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"label\"] = pd.np.where(reviews[\"stars\"] >= 4, \"pos\", \"neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo la distribuzione tra recensioni positive e negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rappresentazione bag of words\n",
    "\n",
    "Per addestrare un modello ML su dei testi è necessario estrarre delle variabili da di essi. Per questo è possibile rappresentare ogni testo in forma di un _bag of words_, ovvero un insieme delle parole contenute in ciascun testo con associato il loro numero di occorrenze. In questo modo da ogni parola distinta (_termine_) presente nei testi è estratta una variabile su cui il modello può apprendere.\n",
    "\n",
    "scikit-learn fornisce la classe `CountVectorizer` per convertire ciascun testo di un insieme dato in un vettore di conteggi delle parole presenti.\n",
    "\n",
    "Per vedere come funziona, creiamo una breve lista di frasi d'esempio da processare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"the sky is blue\",\n",
    "    \"sky is blue and sky is beautiful\",\n",
    "    \"the beautiful sky is so blue\",\n",
    "    \"i love blue cheese\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per convertire tali frasi in bag of words, creiamo prima un oggetto `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto passiamo la lista di frasi a tale oggetto usando la funzione `fit_transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vect.fit_transform(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'oggetto `dtm` ottenuto è una _matrice documenti-termini_, che contiene una riga per ogni documento e una colonna per ogni termine: ogni suo valore indica il numero di occorrenze di un termine in un documento. Visualizziamo tale matrice..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice indica ad esempio che la seconda frase (\"sky is blue and sky is beautiful\") contiene tra le altre la parola \"sky\" 2 volte e la parola \"blue\" 1 volta. I termini utilizzati come variabili sono tutti quelli presenti nei testi passati alla funzione `fit_transform`. Data una nuova frase d'esempio..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_example = \"loving this blue sky today\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...è possibile usare la funzione `transform` per estrarne il bag of words mantenendo inalterato il set di variabili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(vect.transform([new_example]).toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si noti che alcune parole della nuova frase (es. \"loving\") vengono \"perse\", in quanto non inizialmente previste tra le variabili. Quando si addestra un modello ML vanno fissate le variabili da utilizzare, per cui qualsiasi termine non presente nei testi usati per addestrare il modello sarà ignorato se trovato nei testi da classificare in seguito.\n",
    "\n",
    "Applichiamo ora `CountVectorizer` ai dati effettivi. Per iniziare dividiamo come al solito i dati a disposizione in training e validation set, individuando come variabile X il testo della recensione e come y l'etichetta \"pos\" o \"neg\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(reviews[\"text\"], reviews[\"label\"], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo ora un nuovo oggetto `CountVectorizer` per questi dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applichiamo prima `fit_transform` ai testi del training set: questo determinerà quali termini saranno usati come variabili e ci restituirà i bag of words delle recensioni di training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_train = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quindi applichiamo `transform` ai testi del validation set: i bag of words di questi saranno basati sulle sole parole viste nel training set, in modo che siano compatibili col modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_val = vect.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addestramento modelli\n",
    "\n",
    "Possiamo ora addestrare un modello di classificazione basato sui bag of words utilizzando gli stessi algoritmi visti sopra. Generiamo ad esempio un albero decisionale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'albero verrà quindi addestrato sui bag of words delle recensioni del training set e sulle relative etichette \"pos\"/\"neg\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dtm_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A questo punto, dato un generico commento da classificare..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_comment = \"A really wonderful movie!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...possiamo convertirlo in bag of words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_comment_bag = vect.transform([my_comment])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...per passarlo al modello e ottenere l'orientamento stimato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(my_comment_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come visto sopra, possiamo anche ottenere le probabilità delle due classi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(my_comment_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello è quindi sicuro al 100% che il commento sia positivo.\n",
    "\n",
    "Come al solito, possiamo effettuare il calcolo dell'accuratezza sul validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(dtm_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello etichetta correttamente circa il 70% delle recensioni di validazione.\n",
    "\n",
    "Testiamo ora invece un modello SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(gamma=\"auto\")\n",
    "model.fit(dtm_train, y_train)\n",
    "model.score(dtm_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo ottenuto un leggero incremento dell'accuratezza.\n",
    "\n",
    "## Riduzione del numero di variabili\n",
    "\n",
    "L'addestramento di modelli sui bag of words delle recensioni ha richiesto molto più tempo rispetto a quello per addestrare modelli simili su dati strutturati. Questo è dovuto all'elevato numero di variabili usate per rappresentare le recensioni. Per vedere tale numero, vediamo quanti termini distinti vengono riconosciuti dall'oggetto `vect`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È possibile ridurre questo numero di variabili - e di conseguenza il tempo necessario per l'addestramento - senza un crollo nell'accuratezza del modello?\n",
    "\n",
    "`CountVectorizer` accetta diverse opzioni per cambiare l'insieme di variabili. Una di queste è `min_df`, che fa sì che le parole che appaiono in un numero di testi inferiore alla soglia data sia scartata.\n",
    "\n",
    "Ripetiamo ad esempio il processo di generazione dei bag of words e addestramento modello selezionando solo le parole che appaiono in almeno 3 recensioni: creiamo un nuovo `CountVectorizer` opportunamente configurato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processiamo i testi di training e validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_train = vect.fit_transform(X_train)\n",
    "dtm_val = vect.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il numero di variabili considerate questa volta è..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addestriamo e valutiamo un nuovo modello basato su questo insieme più ristretto di variabili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(gamma=\"auto\")\n",
    "model.fit(dtm_train, y_train)\n",
    "model.score(dtm_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accuratezza è rimasta invariata nonostante il numero di variabili si sia più che dimezzato.\n",
    "\n",
    "Un altro accorgimento per ridurre le variabili è la rimozione delle _stopword_, ovvero parole come articoli e congiunzioni (\"e\", \"ma\", \"il\", ...) che prese da sole in genere non forniscono alcuna informazione sul contenuto del testo. scikit-learn include una lista di stopword inglesi, si può impostare `CountVectorizer` in modo che le rimuova con l'opzione `stop_words=\"english\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=3, stop_words=\"english\")\n",
    "dtm_train = vect.fit_transform(X_train)\n",
    "dtm_val = vect.transform(X_val)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(gamma=\"auto\")\n",
    "model.fit(dtm_train, y_train)\n",
    "model.score(dtm_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anche la rimozione delle stopword ha ridotto il numero di feature senza far calare l'accuratezza.\n",
    "\n",
    "Esistono molte altre tecniche per rendere la classificazione di testi più accurata e/o più efficiente, tra cui l'uso del _tf.idf_ per valutare meglio l'importanza delle parole nei testi e dello _stemming_ per raggruppare in uno stesso termine parole con la stessa radice morfologica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizi suggeriti\n",
    "\n",
    "- Testare diverse combinazioni di parametri di `CountVectorizer` con diversi modelli di classificazione\n",
    "- Testare i modelli con frasi specifiche cercando di capire in quali casi sbagliano: ad esempio, non considerando l'ordine delle parole, è plausibile che singole frasi con negazioni come \"not a bad movie\" non vengano comprese"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IFTS",
   "language": "python",
   "name": "ifts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
